{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import Libs","metadata":{}},{"cell_type":"code","source":"import os\nimport warnings # 避免一些可以忽略的报错\nwarnings.filterwarnings('ignore')\nimport random\nimport gc\nimport copy\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm # 进度条\nimport time\nimport math\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\nfrom torch.optim import lr_scheduler # 学习率调度器\nfrom torch.optim.lr_scheduler import _LRScheduler, CosineAnnealingLR\n\nimport timm # 预训练神经网络库，可直接调用预训练好的模型\nfrom PIL import Image\nimport albumentations as A # 数据增强库\nfrom albumentations.pytorch import ToTensorV2\nfrom sklearn.model_selection import StratifiedKFold # 贴 kfold, 部分任务可能需要用到 StratifiedGroupKFold 将同一个group分到同一个fold中以防止数据泄露\nfrom sklearn.preprocessing import OneHotEncoder # 独热编码\n\nfrom collections import defaultdict # 记录 loss lr 等相关参数的变化\n# 改变 终端颜色 方便观察\nfrom colorama import Fore, Back, Style\nb_ = Fore.BLUE\nsr_ = Style.RESET_ALL","metadata":{"execution":{"iopub.status.busy":"2024-11-01T06:24:07.537883Z","iopub.execute_input":"2024-11-01T06:24:07.538577Z","iopub.status.idle":"2024-11-01T06:24:19.148602Z","shell.execute_reply.started":"2024-11-01T06:24:07.538531Z","shell.execute_reply":"2024-11-01T06:24:19.147793Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## CONFIG","metadata":{}},{"cell_type":"code","source":"is_debug = False\n\nclass CONFIG:\n    seed = 308\n    n_folds = 5\n    \n    epochs = 10 if not is_debug else 2\n    now_cv = 0\n    \n    is_DataParallel = True\n    img_size = [28, 28]\n    new_size2train = [32, 32]\n    train_batch_size = 256\n    valid_batch_size = 512\n    labelsmooth_threshold = 0.09 # 标签平滑的阈值\n    \n    n_classes = 10\n\n    n_workers = os.cpu_count() // 2 # 获取此设备上的 CPU 核心数,使用一半到 DataLoader 的 num_workers\n    \n    learning_rate = 1e-3\n    weight_decay = 1e-6 # 一个参数而已\n    scheduler = 'CosineAnnealingWithWarmupLR' # 带热身的优化器\n    # T_max : 经过多少 step 降到最低，训练一批 batch 为一个 step，一般训练到最后降到最低 所以可以根据训练数据量动态调整\n    T_max = 42000 // n_folds * (n_folds - 1) // train_batch_size * epochs \n    # 33600为train.csv中80%的数据量个数即训练数据量，一轮 (33600 // train_batch_size)个 batch，一共(33600 // train_batch_size) * epochs 个 batch\n    min_lr = 1e-6\n    \n    \n    \"\"\"\n    tf_efficientnet_b0.ns_jft_in1k\n    tf_efficientnetv2_s.in21k_ft_in1k\n    \n    convnext_tiny.fb_in22k_ft_in1k_384\n    convnext_atto.d2_in1k\n    \n    tiny_vit_21m_512.dist_in22k_ft_in1k\n    # 一般的 vit 模型会限制输入指定大小的图像如 224、384、512等，而 tiny_vit 在拥有优越性能的同时不限制输入大小(推荐使用，但是显存占用会大一点)\n    \"\"\"\n    model_name = \"convnext_atto.d2_in1k\"\n    pool_name = \"\" # 最后的全局池化层使用默认的池化层\n    timm_pretrained = True # 是否使用预训练模型设置为 True，表示使用预训练模型\n    \n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    \n    train_csv = \"/kaggle/input/digit-recognizer/train.csv\"\n    my_train_csv = \"/kaggle/input/my-digit-recognizer-5skf-train-csv/my_digit_recognizer_5skf.csv\" # 与 train.csv的唯一区别是多了一列 kfold\n    img_path = \"/kaggle/input/308-digit-recognizer-img/output\"\n    ckpt_save_path = \"/kaggle/working/output\"","metadata":{"execution":{"iopub.status.busy":"2024-11-01T06:28:22.990092Z","iopub.execute_input":"2024-11-01T06:28:22.990497Z","iopub.status.idle":"2024-11-01T06:28:22.999965Z","shell.execute_reply.started":"2024-11-01T06:28:22.990458Z","shell.execute_reply":"2024-11-01T06:28:22.998904Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Set Random Seed","metadata":{}},{"cell_type":"code","source":"def set_seed(seed=308):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nset_seed(CONFIG.seed) # 固定随机种子，方便结果复现","metadata":{"execution":{"iopub.status.busy":"2024-11-01T06:24:19.208109Z","iopub.execute_input":"2024-11-01T06:24:19.208408Z","iopub.status.idle":"2024-11-01T06:24:19.245013Z","shell.execute_reply.started":"2024-11-01T06:24:19.208377Z","shell.execute_reply":"2024-11-01T06:24:19.244205Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Data Progress","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(CONFIG.train_csv) # 读取训练的 .csv\ntrain","metadata":{"execution":{"iopub.status.busy":"2024-11-01T06:24:19.246940Z","iopub.execute_input":"2024-11-01T06:24:19.247228Z","iopub.status.idle":"2024-11-01T06:24:22.988158Z","shell.execute_reply.started":"2024-11-01T06:24:19.247198Z","shell.execute_reply":"2024-11-01T06:24:22.987148Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"       label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n0          1       0       0       0       0       0       0       0       0   \n1          0       0       0       0       0       0       0       0       0   \n2          1       0       0       0       0       0       0       0       0   \n3          4       0       0       0       0       0       0       0       0   \n4          0       0       0       0       0       0       0       0       0   \n...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n41995      0       0       0       0       0       0       0       0       0   \n41996      1       0       0       0       0       0       0       0       0   \n41997      7       0       0       0       0       0       0       0       0   \n41998      6       0       0       0       0       0       0       0       0   \n41999      9       0       0       0       0       0       0       0       0   \n\n       pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n0           0  ...         0         0         0         0         0   \n1           0  ...         0         0         0         0         0   \n2           0  ...         0         0         0         0         0   \n3           0  ...         0         0         0         0         0   \n4           0  ...         0         0         0         0         0   \n...       ...  ...       ...       ...       ...       ...       ...   \n41995       0  ...         0         0         0         0         0   \n41996       0  ...         0         0         0         0         0   \n41997       0  ...         0         0         0         0         0   \n41998       0  ...         0         0         0         0         0   \n41999       0  ...         0         0         0         0         0   \n\n       pixel779  pixel780  pixel781  pixel782  pixel783  \n0             0         0         0         0         0  \n1             0         0         0         0         0  \n2             0         0         0         0         0  \n3             0         0         0         0         0  \n4             0         0         0         0         0  \n...         ...       ...       ...       ...       ...  \n41995         0         0         0         0         0  \n41996         0         0         0         0         0  \n41997         0         0         0         0         0  \n41998         0         0         0         0         0  \n41999         0         0         0         0         0  \n\n[42000 rows x 785 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>41995</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>41996</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>41997</th>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>41998</th>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>41999</th>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>42000 rows × 785 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"if os.path.exists(CONFIG.my_train_csv) is False: # 对 train.csv贴 kfold并保存方便后续训练使用\n    print(\"my_train_csv not exists... \\nnew_train_csv_with_fold generating...\")\n    # 初始化 StratifiedKFold\n    skf = StratifiedKFold(n_splits=CONFIG.n_folds, shuffle=True, random_state=CONFIG.seed)\n\n    # 创建新的 kfold 列，并初始化为 -1\n    train['kfold'] = -1\n\n    # 填充 kfold 列\n    for fold, (train_idx, val_idx) in enumerate(skf.split(X=train, y=train['label'])):\n        train.loc[val_idx, 'kfold'] = fold\n        \n    train.to_csv(\"my_digit_recognizer_5skf.csv\", index=False)\n    \nelse: # 如果 my_train_csv存在，直接读取使用 (对每一次训练使用同一个.csv文件是为了有相同的 kfold，这样可以避免数据泄露，翻遍后续模型融合)\n    print(\"my_train_csv exists... \\nreading...\")\n    train = pd.read_csv(CONFIG.my_train_csv)\n    \ntrain","metadata":{"execution":{"iopub.status.busy":"2024-11-01T06:35:33.879338Z","iopub.execute_input":"2024-11-01T06:35:33.879715Z","iopub.status.idle":"2024-11-01T06:35:36.329018Z","shell.execute_reply.started":"2024-11-01T06:35:33.879678Z","shell.execute_reply":"2024-11-01T06:35:36.328014Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"my_train_csv exists... \nreading...\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"       label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n0          1       0       0       0       0       0       0       0       0   \n1          0       0       0       0       0       0       0       0       0   \n2          1       0       0       0       0       0       0       0       0   \n3          4       0       0       0       0       0       0       0       0   \n4          0       0       0       0       0       0       0       0       0   \n...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n41995      0       0       0       0       0       0       0       0       0   \n41996      1       0       0       0       0       0       0       0       0   \n41997      7       0       0       0       0       0       0       0       0   \n41998      6       0       0       0       0       0       0       0       0   \n41999      9       0       0       0       0       0       0       0       0   \n\n       pixel8  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0           0  ...         0         0         0         0         0   \n1           0  ...         0         0         0         0         0   \n2           0  ...         0         0         0         0         0   \n3           0  ...         0         0         0         0         0   \n4           0  ...         0         0         0         0         0   \n...       ...  ...       ...       ...       ...       ...       ...   \n41995       0  ...         0         0         0         0         0   \n41996       0  ...         0         0         0         0         0   \n41997       0  ...         0         0         0         0         0   \n41998       0  ...         0         0         0         0         0   \n41999       0  ...         0         0         0         0         0   \n\n       pixel780  pixel781  pixel782  pixel783  kfold  \n0             0         0         0         0      2  \n1             0         0         0         0      1  \n2             0         0         0         0      2  \n3             0         0         0         0      4  \n4             0         0         0         0      2  \n...         ...       ...       ...       ...    ...  \n41995         0         0         0         0      4  \n41996         0         0         0         0      4  \n41997         0         0         0         0      1  \n41998         0         0         0         0      4  \n41999         0         0         0         0      1  \n\n[42000 rows x 786 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n      <th>kfold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>41995</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>41996</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>41997</th>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>41998</th>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>41999</th>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>42000 rows × 786 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Dataset and DataLoader","metadata":{}},{"cell_type":"code","source":"def transform_train(img):\n    composition = A.Compose([\n        A.OneOf([\n            A.MotionBlur(blur_limit=5),\n            A.MedianBlur(blur_limit=5),\n            A.GaussianBlur(blur_limit=5),\n            A.GaussNoise(var_limit=(5.0, 30.0)),\n        ], p=0.7),\n        # albumentations 数据增强库的其他功能参考：https://blog.csdn.net/qq_27039891/article/details/100795846?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522613472AB-3AB7-4407-9825-DA5DD079F755%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=613472AB-3AB7-4407-9825-DA5DD079F755&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-5-100795846-null-null.142^v100^pc_search_result_base1&utm_term=albumentations%20%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA&spm=1018.2226.3001.4187\n        \n        A.Resize(CONFIG.new_size2train[0], CONFIG.new_size2train[0]),\n        A.Normalize(),\n        ToTensorV2(),\n    ])\n    return composition(image=img)[\"image\"]\n\ndef transform_valid(img):\n    composition = A.Compose([\n        A.Resize(CONFIG.new_size2train[0], CONFIG.new_size2train[0]),\n        A.Normalize(),\n        ToTensorV2(),\n    ])\n    return composition(image=img)[\"image\"]","metadata":{"execution":{"iopub.status.busy":"2024-10-31T13:26:56.238157Z","iopub.execute_input":"2024-10-31T13:26:56.239059Z","iopub.status.idle":"2024-10-31T13:26:56.246563Z","shell.execute_reply.started":"2024-10-31T13:26:56.239010Z","shell.execute_reply":"2024-10-31T13:26:56.245500Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 标签数据，示例为 0 到 9 的标签\nlabels = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]).reshape(-1, 1)\n\n# 初始化 OneHotEncoder\nencoder = OneHotEncoder(sparse=False)\none_hot = encoder.fit_transform(labels)\n\n# print(one_hot)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T13:26:56.249207Z","iopub.execute_input":"2024-10-31T13:26:56.249567Z","iopub.status.idle":"2024-10-31T13:26:56.264707Z","shell.execute_reply.started":"2024-10-31T13:26:56.249532Z","shell.execute_reply":"2024-10-31T13:26:56.263060Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, df, transform=None, mode=\"train\"):\n        super().__init__()\n        self.df = df\n        self.transform = transform\n        self.mode = mode\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx, :] # 从 df 中取出 idx 这一行\n        label = row.label\n        \n        label_onehot = encoder.transform(np.array(label).reshape(-1, 1))[0] # 将原标签转换成独热编码格式\n        if self.mode == \"train\": # 标签平滑只在训练阶段进行，验证阶段不涉及标签平滑\n            # 标签平滑\n            label_onehot[label] = label_onehot[label] - CONFIG.labelsmooth_threshold # 让正确标签 减去阈值\n            label_onehot[label_onehot == 0] = CONFIG.labelsmooth_threshold / (CONFIG.n_classes - 1) # 再将减去的阈值平均分给其他 9个标签\n            label = label_onehot\n        elif self.mode == \"valid\":\n            label = label_onehot\n        else:\n            raise(\"mode not train or valid\")\n        \n        img = row[\"pixel0\": \"pixel783\"].values\n        img = img.reshape(CONFIG.img_size[0], CONFIG.img_size[1], -1)\n        img = np.concatenate([img] * 3, axis=-1).astype(np.uint8) # Albumentations 中的部分数据增强操作需要图像为 uint8 数据类型才能执行 \n        \n        if self.transform != None: # 可进行 totensor 数据增强 等操作\n            img = self.transform(img) # ToTensor操作可自动将最后一维的 channel 提前，即 (H, W, C) --> (C, H, W)\n        \n        return img, label # Dataset 一般一次返回一条 X(特征), y(标签) 这样的形式","metadata":{"execution":{"iopub.status.busy":"2024-10-31T13:26:56.266200Z","iopub.execute_input":"2024-10-31T13:26:56.266542Z","iopub.status.idle":"2024-10-31T13:26:56.277928Z","shell.execute_reply.started":"2024-10-31T13:26:56.266508Z","shell.execute_reply":"2024-10-31T13:26:56.276487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_loaders(df, fold=0):\n    df_train = df[df[\"kfold\"] != fold]\n    df_valid = df[df[\"kfold\"] == fold]\n    \n    train_datasets = MyDataset(df=df_train, transform=transform_train, mode=\"train\")\n    valid_datasets = MyDataset(df=df_valid, transform=transform_valid, mode=\"valid\")\n    \n    train_loader = DataLoader(train_datasets, batch_size=CONFIG.train_batch_size, num_workers=CONFIG.n_workers, shuffle=True, pin_memory=True)\n    valid_loader = DataLoader(valid_datasets, batch_size=CONFIG.valid_batch_size, num_workers=CONFIG.n_workers, shuffle=False, pin_memory=True)\n    # valid_loader 一般不行打乱操作 所以 shuffle 为 False\n    \n    return train_loader, valid_loader","metadata":{"execution":{"iopub.status.busy":"2024-10-31T13:26:56.279716Z","iopub.execute_input":"2024-10-31T13:26:56.280145Z","iopub.status.idle":"2024-10-31T13:26:56.289902Z","shell.execute_reply.started":"2024-10-31T13:26:56.280079Z","shell.execute_reply":"2024-10-31T13:26:56.288824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 以下代码可检查Dataset，DataLoader是否实现基本功能\ntrain_loader, valid_loader = prepare_loaders(train, 0)\nx_train, y_train = next(iter(train_loader))\nx_valid, y_valid = next(iter(valid_loader))\nprint(f\"X_train shape : {x_train.shape}\") # (batch_size, channels, H, W)\nprint(f\"y_train shape : {y_train.shape}\")\nprint(f\"x_valid shape : {x_valid.shape}\")\nprint(f\"y_valid shape : {y_valid.shape}\")\n\n# 删除变量，回收垃圾\ndel train_loader, valid_loader, x_train, y_train, x_valid, y_valid\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-10-31T13:26:56.291336Z","iopub.execute_input":"2024-10-31T13:26:56.291750Z","iopub.status.idle":"2024-10-31T13:27:01.526551Z","shell.execute_reply.started":"2024-10-31T13:26:56.291710Z","shell.execute_reply":"2024-10-31T13:27:01.525161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluation","metadata":{}},{"cell_type":"code","source":"def cal_ACC(y_true, y_preds):\n    if len(y_true) != len(y_preds):\n        raise(\"len(y_true) != len(y_preds)\")\n    length = len(y_true)\n    acc = (y_true == y_preds).sum() / length\n    \n    return acc","metadata":{"execution":{"iopub.status.busy":"2024-10-31T13:27:01.528359Z","iopub.execute_input":"2024-10-31T13:27:01.528883Z","iopub.status.idle":"2024-10-31T13:27:01.536615Z","shell.execute_reply.started":"2024-10-31T13:27:01.528817Z","shell.execute_reply":"2024-10-31T13:27:01.535309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"class GeMPool(nn.Module):\n    def __init__(self, p=3, eps=1e-6):\n        super(GeMPool, self).__init__()\n        self.p = nn.Parameter(torch.ones(1) * p)\n        self.eps = eps\n\n    def forward(self, x):\n        return self.gem(x, p=self.p, eps=self.eps)\n    \n    def gem(self, x, p=3, eps=1e-6):\n        return torch.mean(x.clamp(min=eps).pow(p), dim=(-2, -1)).pow(1./p)\n    \n    def __repr__(self):\n        return self.__class__.__name__ + f'(p={self.p.data.tolist()[0]:.4f}, eps={self.eps})'","metadata":{"execution":{"iopub.status.busy":"2024-10-31T13:27:01.539282Z","iopub.execute_input":"2024-10-31T13:27:01.539640Z","iopub.status.idle":"2024-10-31T13:27:01.558956Z","shell.execute_reply.started":"2024-10-31T13:27:01.539607Z","shell.execute_reply":"2024-10-31T13:27:01.557760Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DigitRecognizerModel(nn.Module):\n    def __init__(self):\n        super(DigitRecognizerModel, self).__init__()\n        # 使用 timm.create_model() 创建模型，将模型名称传入 model_name 即可完成创建，pretrained 参数默认为 False，这里我们改为True使用预训练权重\n        self.backbone = timm.create_model(model_name=CONFIG.model_name, pretrained=CONFIG.timm_pretrained)\n            \n        #############################################################################################################################\n        # 最后的 head 层\n        if \"efficientnet\" in CONFIG.model_name:\n            if CONFIG.pool_name == \"GeMPool\":\n                self.backbone.global_pool = GeMPool() # 修改 最后的全局池化层为 GeMPooling\n            in_features = self.backbone.classifier.in_features # 将预训练模型的最后一层的输出参数取出\n            self.backbone.classifier = nn.Identity() # nn.Identity() 输入什么就输出什么，这里相当于将模型中的 classifier 层去掉\n            \n        elif \"vit\" in CONFIG.model_name:\n            in_features = self.backbone.head.fc.in_features\n            self.backbone.head.fc = nn.Identity()\n            \n        elif \"convnext\" in CONFIG.model_name:\n            in_features = self.backbone.head.fc.in_features\n            self.backbone.head.fc = nn.Identity()\n        #############################################################################################################################\n        \n        self.head = nn.Sequential( # 用自定义的 head 层代替原模型中的 classifier 分类层\n            nn.Linear(in_features, CONFIG.n_classes)\n        )\n        \n        \n    def forward(self, x):\n        output = self.backbone(x) # 经过预训练的 模型主干backbone 后得到高级语义信息\n        output = self.head(output) # 将高级语义信息传入给分类头进行最后的分类输出\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-10-31T13:27:40.687502Z","iopub.execute_input":"2024-10-31T13:27:40.687925Z","iopub.status.idle":"2024-10-31T13:27:40.697257Z","shell.execute_reply.started":"2024-10-31T13:27:40.687887Z","shell.execute_reply":"2024-10-31T13:27:40.696068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = DigitRecognizerModel() # 实例化模型\nmodel.to(CONFIG.device)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-10-31T13:27:41.814298Z","iopub.execute_input":"2024-10-31T13:27:41.814708Z","iopub.status.idle":"2024-10-31T13:27:42.044290Z","shell.execute_reply.started":"2024-10-31T13:27:41.814664Z","shell.execute_reply":"2024-10-31T13:27:42.042805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train and Valid Function","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss() # 实例化损失函数 多分类可选 交叉熵损失","metadata":{"execution":{"iopub.status.busy":"2024-10-28T11:35:06.736534Z","iopub.execute_input":"2024-10-28T11:35:06.736901Z","iopub.status.idle":"2024-10-28T11:35:06.741365Z","shell.execute_reply.started":"2024-10-28T11:35:06.736868Z","shell.execute_reply":"2024-10-28T11:35:06.740349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_one_epoch(model, optimizer, scheduler, train_loader, epoch):\n    model.train()\n    \n    y_preds = []\n    y_trues = []\n    \n    dataset_size = 0\n    running_loss = 0.0\n    bar = tqdm(enumerate(train_loader), total=len(train_loader)) # 进度条\n    for step, (images, labels) in bar:\n        optimizer.zero_grad()\n        \n        batch_size = images.size(0)        \n        if CONFIG.is_DataParallel: # 使用多卡并行训练\n            images = images.cuda().float()\n            labels = labels.cuda().float() # 使用标签平滑操作，此处标签为独热编码，所以用 float32数据类型\n        else: # 使用单卡训练\n            images = images.to(CONFIG.device, dtype=torch.float)\n            labels = labels.to(CONFIG.device, dtype=torch.float) # 使用标签平滑操作，此处标签为独热编码，所以用 float32数据类型\n        \n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        \n        optimizer.step()\n        if scheduler is not None:\n            scheduler.step()\n\n        y_preds.append(outputs.argmax(1).detach().cpu().numpy())\n        y_trues.append(labels.argmax(1).detach().cpu().numpy())\n        _y_preds = np.concatenate(y_preds)\n        _y_trues = np.concatenate(y_trues)\n\n        train_cv = cal_ACC(_y_trues, _y_preds)\n\n        running_loss += (loss.item() * batch_size)\n\n        dataset_size += batch_size\n        \n        epoch_loss = running_loss / dataset_size\n        \n        # 设置让进度条显示的数据\n        bar.set_postfix(Epoch=epoch,\n                        Train_Loss=epoch_loss,\n                        Train_ACC=train_cv,\n                        LR=optimizer.param_groups[0]['lr'])\n \n    return epoch_loss, train_cv","metadata":{"execution":{"iopub.status.busy":"2024-10-28T11:35:07.038708Z","iopub.execute_input":"2024-10-28T11:35:07.039417Z","iopub.status.idle":"2024-10-28T11:35:07.050216Z","shell.execute_reply.started":"2024-10-28T11:35:07.039365Z","shell.execute_reply":"2024-10-28T11:35:07.049230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@torch.inference_mode()\ndef valid_one_epoch(model, valid_loader, epoch):\n    model.eval()\n    \n    y_preds = []\n    y_trues = []\n    dataset_size = 0\n    running_loss = 0.0\n    bar = tqdm(enumerate(valid_loader), total=len(valid_loader))\n    with torch.no_grad():\n        for step, (images, labels) in bar:\n            batch_size = images.size(0)\n            \n            if CONFIG.is_DataParallel:\n                images = images.cuda().float()\n                labels = labels.cuda().float()\n            else:\n                images = images.to(CONFIG.device, dtype=torch.float)\n                labels = labels.to(CONFIG.device, dtype=torch.float)\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            y_preds.append(outputs.argmax(1).detach().cpu().numpy())\n            y_trues.append(labels.argmax(1).detach().cpu().numpy())\n            _y_preds = np.concatenate(y_preds)\n            _y_trues = np.concatenate(y_trues)\n            \n            valid_cv = cal_ACC(_y_trues, _y_preds)\n        \n            running_loss += (loss.item() * batch_size)\n\n            dataset_size += batch_size\n\n            epoch_loss = running_loss / dataset_size\n\n            bar.set_postfix(Epoch=epoch,\n                            Valid_Loss=epoch_loss,\n                            Valid_ACC=valid_cv,\n                            LR=optimizer.param_groups[0]['lr'])\n\n    return epoch_loss, valid_cv","metadata":{"execution":{"iopub.status.busy":"2024-10-28T11:35:07.371384Z","iopub.execute_input":"2024-10-28T11:35:07.371693Z","iopub.status.idle":"2024-10-28T11:35:07.381969Z","shell.execute_reply.started":"2024-10-28T11:35:07.371661Z","shell.execute_reply":"2024-10-28T11:35:07.381053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_training(fold, model, optimizer, scheduler, train_loader, valid_loader, num_epochs=CONFIG.epochs, now_cv=CONFIG.now_cv):\n    if torch.cuda.is_available():\n        print(\"[INFO] Using GPU: {} x {}\\n\".format(torch.cuda.get_device_name(), torch.cuda.device_count()))\n    \n    start = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict()) # 用于 存储最好的 cv 的模型权重\n    best_epoch_cv = now_cv\n    best_model_path = None # # 用于 存储最好的 cv 的模型权重的路径\n    history = defaultdict(list)\n    \n    for epoch in range(1, num_epochs + 1):\n        gc.collect() # 立即回收，清除缓存中的垃圾\n        train_epoch_loss, train_epoch_cv = train_one_epoch(model, optimizer, scheduler, train_loader, epoch)\n        valid_epoch_loss, valid_epoch_cv = valid_one_epoch(model, valid_loader, epoch)\n        print(f\"epoch: {epoch}, LOSS = {valid_epoch_loss}, CV(Acc) = {valid_epoch_cv}\")\n        \n        history['Train Loss'].append(train_epoch_loss)\n        history['Valid Loss'].append(valid_epoch_loss)\n        history['Train CV(Acc)'].append(train_epoch_cv)\n        history['Valid CV(Acc)'].append(valid_epoch_cv)\n        history['lr'].append(optimizer.param_groups[0]['lr'])\n        \n        # deep copy the model\n        if valid_epoch_cv >= best_epoch_cv:\n            print(f\"{b_}epoch: {epoch}, Validation CV(Acc) Improved ({best_epoch_cv} ---> {valid_epoch_cv}))\")\n            best_epoch_cv = valid_epoch_cv\n            best_model_wts = copy.deepcopy(model.state_dict())\n            if os.path.exists(CONFIG.ckpt_save_path) is False: # 如果该路径不存在，创建相关路径\n                os.makedirs(CONFIG.ckpt_save_path)\n                \n            PATH = \"{}/Fold_{}_CV_{:.4f}_Loss{:.4f}_epoch{:.0f}.bin\".format(CONFIG.ckpt_save_path, fold, best_epoch_cv, valid_epoch_loss, epoch)\n            best_model_path = PATH\n            torch.save(model.state_dict(), PATH) # 只保存模型的权重参数到指定路径\n            print(f\"Model Saved{sr_}\")\n            \n        print()\n    \n    # 计算训练总消耗时间\n    end = time.time()\n    time_elapsed = end - start\n    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n    print(\"Best CV(Acc): {:.4f}\".format(best_epoch_cv))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n\n    return model, history, best_model_path","metadata":{"execution":{"iopub.status.busy":"2024-10-28T11:35:08.554011Z","iopub.execute_input":"2024-10-28T11:35:08.554982Z","iopub.status.idle":"2024-10-28T11:35:08.567553Z","shell.execute_reply.started":"2024-10-28T11:35:08.554934Z","shell.execute_reply":"2024-10-28T11:35:08.566520Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Optimizer","metadata":{}},{"cell_type":"code","source":"class CosineAnnealingWithWarmupLR(_LRScheduler):\n    def __init__(self, optimizer, T_max, eta_min=0, warmup_epochs=10, last_epoch=-1):\n        self.T_max = T_max\n        self.eta_min = eta_min\n        self.warmup_epochs = warmup_epochs\n        self.cosine_epochs = T_max - warmup_epochs\n        super(CosineAnnealingWithWarmupLR, self).__init__(optimizer, last_epoch)\n\n    def get_lr(self):\n        if self.last_epoch < self.warmup_epochs:\n            # Linear warmup\n            return [(base_lr * (self.last_epoch + 1) / self.warmup_epochs) for base_lr in self.base_lrs]\n        else:\n            # Cosine annealing\n            cosine_epoch = self.last_epoch - self.warmup_epochs\n            return [self.eta_min + (base_lr - self.eta_min) * (1 + math.cos(math.pi * cosine_epoch / self.cosine_epochs)) / 2 for base_lr in self.base_lrs]","metadata":{"execution":{"iopub.status.busy":"2024-10-28T11:35:09.407717Z","iopub.execute_input":"2024-10-28T11:35:09.408597Z","iopub.status.idle":"2024-10-28T11:35:09.416183Z","shell.execute_reply.started":"2024-10-28T11:35:09.408553Z","shell.execute_reply":"2024-10-28T11:35:09.415119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lr scheduler\ndef fetch_scheduler(optimizer, T_max, min_lr):\n    if CONFIG.scheduler == 'CosineAnnealingLR': # 学习率根据 cos 函数特性下降，可以观察最后 logs 画出来的图像中 学习率的变化\n        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=T_max, \n                                                   eta_min=min_lr)\n    elif CONFIG.scheduler == 'CosineAnnealingWithWarmupLR':\n        scheduler = CosineAnnealingWithWarmupLR(optimizer, T_max=T_max, eta_min=min_lr, \n                                                warmup_epochs=T_max//CONFIG.epochs)\n    elif CONFIG.scheduler == None:\n        return None\n        \n    return scheduler","metadata":{"execution":{"iopub.status.busy":"2024-10-28T11:35:10.931624Z","iopub.execute_input":"2024-10-28T11:35:10.932004Z","iopub.status.idle":"2024-10-28T11:35:10.937796Z","shell.execute_reply.started":"2024-10-28T11:35:10.931968Z","shell.execute_reply":"2024-10-28T11:35:10.936840Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 指定优化器为 AdamW\n# optimizer = torch.optim.AdamW(model.parameters(), lr=CONFIG.learning_rate, \n#                              weight_decay=CONFIG.weight_decay)\n# scheduler = fetch_scheduler(optimizer, T_max=CONFIG.T_max, min_lr=CONFIG.min_lr)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T11:35:12.510490Z","iopub.execute_input":"2024-10-28T11:35:12.510881Z","iopub.status.idle":"2024-10-28T11:35:12.514956Z","shell.execute_reply.started":"2024-10-28T11:35:12.510846Z","shell.execute_reply":"2024-10-28T11:35:12.514049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Start Training","metadata":{}},{"cell_type":"code","source":"oof = []\ntrue = []\nhistorys = []\n\nfor fold in range(CONFIG.n_folds):\n    print(f\"================================ Fold {fold} start training ================================\")\n    del model # 将上一个fold的模型删除，重新初始化模型训练当前的fold\n    torch.cuda.empty_cache()\n    model = DigitRecognizerModel()\n    if CONFIG.is_DataParallel:\n        device_ids = [0, 1] # 一共使用两张卡，编号为 0和1\n        model = torch.nn.DataParallel(model, device_ids=device_ids) # 将模型并行化到2张卡上\n        model = model.cuda()\n    else:\n        model = model.to(CONFIG.device)\n        \n    optimizer = torch.optim.AdamW(model.parameters(), lr=CONFIG.learning_rate, \n                                  weight_decay=CONFIG.weight_decay)\n    scheduler = fetch_scheduler(optimizer, T_max=CONFIG.T_max, min_lr=CONFIG.min_lr)\n    \n    train_loader, valid_loader = prepare_loaders(train, fold)\n    model, history, best_model_path = run_training(fold, model, optimizer, scheduler, train_loader, valid_loader, \n                                                   num_epochs=CONFIG.epochs, now_cv=CONFIG.now_cv)\n    historys.append(history)\n    \n    # 这一个fold的训练完成后，对这个fold的验证集进行推理，用于计算后面的 oof折外预测\n    bar = tqdm(enumerate(valid_loader), total=len(valid_loader))\n    with torch.no_grad():\n        for step, (images, labels) in bar:\n            batch_size = images.size(0)\n            if CONFIG.is_DataParallel:\n                images = images.cuda().float()\n                labels = labels.cuda().float()\n            else:\n                images = images.to(CONFIG.device, dtype=torch.float)\n                labels = labels.to(CONFIG.device, dtype=torch.float)\n\n            outputs = model(images)\n            outputs = F.softmax(outputs).argmax(1)\n            \n            oof.append(outputs.flatten().detach().cpu().numpy())\n            true.append(labels.detach().cpu().numpy().argmax(1))\n        print() # 换行","metadata":{"execution":{"iopub.status.busy":"2024-10-28T11:35:13.829742Z","iopub.execute_input":"2024-10-28T11:35:13.830373Z","iopub.status.idle":"2024-10-28T11:48:34.274683Z","shell.execute_reply.started":"2024-10-28T11:35:13.830332Z","shell.execute_reply":"2024-10-28T11:48:34.273589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Local CV","metadata":{}},{"cell_type":"code","source":"oof = np.concatenate(oof)\ntrue = np.concatenate(true)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T11:48:38.798615Z","iopub.execute_input":"2024-10-28T11:48:38.799360Z","iopub.status.idle":"2024-10-28T11:48:38.805357Z","shell.execute_reply.started":"2024-10-28T11:48:38.799311Z","shell.execute_reply":"2024-10-28T11:48:38.804270Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"local_cv = cal_ACC(true, oof)\nprint(\"Local CV : \", local_cv)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T11:48:42.126534Z","iopub.execute_input":"2024-10-28T11:48:42.127164Z","iopub.status.idle":"2024-10-28T11:48:42.132305Z","shell.execute_reply.started":"2024-10-28T11:48:42.127126Z","shell.execute_reply":"2024-10-28T11:48:42.131299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Logs","metadata":{}},{"cell_type":"code","source":"fold = 0\nhistory = historys[fold]","metadata":{"execution":{"iopub.status.busy":"2024-10-28T11:48:46.884489Z","iopub.execute_input":"2024-10-28T11:48:46.884879Z","iopub.status.idle":"2024-10-28T11:48:46.889348Z","shell.execute_reply.started":"2024-10-28T11:48:46.884843Z","shell.execute_reply":"2024-10-28T11:48:46.888381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot( range(len(history[\"Train Loss\"])), history[\"Train Loss\"], label=\"Train Loss\")\nplt.plot( range(len(history[\"Valid Loss\"])), history[\"Valid Loss\"], label=\"Valid Loss\")\nplt.xlabel(\"epochs\")\nplt.ylabel(\"Loss\")\nplt.grid()\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-28T11:48:47.979559Z","iopub.execute_input":"2024-10-28T11:48:47.980387Z","iopub.status.idle":"2024-10-28T11:48:48.279513Z","shell.execute_reply.started":"2024-10-28T11:48:47.980344Z","shell.execute_reply":"2024-10-28T11:48:48.278573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot( range(len(history[\"Train CV(Acc)\"])), history[\"Train CV(Acc)\"], label=\"Train CV(Acc)\")\nplt.plot( range(len(history[\"Valid CV(Acc)\"])), history[\"Valid CV(Acc)\"], label=\"Valid CV(Acc)\")\nplt.xlabel(\"epochs\")\nplt.ylabel(\"CV(Acc)\")\nplt.grid()\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-28T11:48:49.230959Z","iopub.execute_input":"2024-10-28T11:48:49.231823Z","iopub.status.idle":"2024-10-28T11:48:49.492472Z","shell.execute_reply.started":"2024-10-28T11:48:49.231781Z","shell.execute_reply":"2024-10-28T11:48:49.491631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot( range(len(history[\"lr\"])), history[\"lr\"], label=\"lr\")\nplt.xlabel(\"epochs\")\nplt.ylabel(\"lr\")\nplt.grid()\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-28T11:48:50.303792Z","iopub.execute_input":"2024-10-28T11:48:50.304592Z","iopub.status.idle":"2024-10-28T11:48:50.484671Z","shell.execute_reply.started":"2024-10-28T11:48:50.304550Z","shell.execute_reply":"2024-10-28T11:48:50.483774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}